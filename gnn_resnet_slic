{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1105687,"sourceType":"datasetVersion","datasetId":619181}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import Required Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow_gnn import layers as gnn_layers\nfrom skimage.segmentation import slic\nfrom skimage.color import rgb2gray\nfrom skimage import io\nimport numpy as np\n\n# Ensure we use GPU if available\ndevice_name = tf.test.gpu_device_name()\nprint(f'Using device: {device_name}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load and Preprocess the Dataset","metadata":{}},{"cell_type":"code","source":"# Define transformation function\ndef load_and_preprocess_image(img_path):\n    img = io.imread(img_path)\n    img = tf.image.resize(img, (224, 224))  # Resize to match input size of pre-trained model\n    img = tf.keras.applications.resnet50.preprocess_input(img)\n    return img\n\ndef load_images_and_labels(dataset_path):\n    images = []\n    labels = []\n    for label in os.listdir(dataset_path):\n        for img_file in os.listdir(os.path.join(dataset_path, label)):\n            img_path = os.path.join(dataset_path, label, img_file)\n            img = load_and_preprocess_image(img_path)\n            images.append(img)\n            labels.append(label)\n    return np.array(images), np.array(labels)\n\ndataset_path = '/kaggle/input/tomatoleaf'\nimages, labels = load_images_and_labels(dataset_path)\n\n# One-hot encode labels for multi-label classification\nlabels = tf.keras.utils.to_categorical(labels, num_classes=10)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define Functions for SLIC Image Segmentation and Feature Extraction","metadata":{}},{"cell_type":"code","source":"def segment_image(image):\n    segments = slic(image, n_segments=100, compactness=10)\n    return segments\n\ndef extract_features(image):\n    model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n    features = model.predict(image)\n    return features.reshape(-1, features.shape[-1])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the GNN Model","metadata":{}},{"cell_type":"code","source":"def create_gnn_model(num_features, num_classes):\n    image_features_input = Input(shape=(224, 224, 3))  # Adjust shape based on your input size\n    node_labels_input = Input(shape=(1,))\n\n    segments = layers.Lambda(lambda x: segment_image(x))(image_features_input)\n    segment_features = layers.Lambda(lambda x: extract_features(x))(segments)\n    node_labels_onehot = layers.OneHot(num_classes, dtype='float32')(node_labels_input)\n\n    node_embeddings = layers.Concatenate()([segment_features, node_labels_onehot])\n\n    x = gnn_layers.GraphConv(128, activation='relu')(node_embeddings)\n    x = gnn_layers.GraphConv(64, activation='relu')(x)\n\n    graph_embedding = layers.GlobalAveragePooling1D()(x)\n    output = layers.Dense(num_classes, activation='sigmoid')(graph_embedding)\n\n    model = tf.keras.Model(inputs=[image_features_input, node_labels_input], outputs=output)\n    return model\n\nmodel = create_gnn_model(2048, 10)  # Assuming 2048 features from ResNet50 and 10 classes\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare Data for Training","metadata":{}},{"cell_type":"code","source":"# Assuming you have train and validation data\nx_train, y_train = images[:800], labels[:800]  # Split the dataset as needed\nx_val, y_val = images[800:], labels[800:]\n\n# Add dummy node labels for this example\nnode_labels_train = np.zeros((x_train.shape[0], 1))\nnode_labels_val = np.zeros((x_val.shape[0], 1))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    model.fit([x_train, node_labels_train], y_train, epochs=10, batch_size=32)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate([x_val, node_labels_val], y_val)\n","metadata":{},"execution_count":null,"outputs":[]}]}