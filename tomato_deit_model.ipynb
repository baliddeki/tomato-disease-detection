{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1105687,"sourceType":"datasetVersion","datasetId":619181}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"name":"tomato_deit_model","provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n# THEN FEEL FREE TO DELETE THIS CELL.\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# NOTEBOOK.\n\nimport os\nimport sys\nfrom tempfile import NamedTemporaryFile\nfrom urllib.request import urlopen\nfrom urllib.parse import unquote, urlparse\nfrom urllib.error import HTTPError\nfrom zipfile import ZipFile\nimport tarfile\nimport shutil\n\nCHUNK_SIZE = 40960\nDATA_SOURCE_MAPPING = 'tomatoleaf:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F619181%2F1105687%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240629%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240629T065839Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4f407181187cab0d90fbef2ad0522f6f1f810c51102bb24fb1203bf7cdb7ba9118993269112a83a69e3c77f030104ce7e37987e1322f33b92d47deef8a2eb5688ef4f2139afa827532baf3f63a8b7d28d0d523f4990c020786d5a02444af2ff32c0aa6293ddb598e51e4d1cff1ccf84e7bf3fa0106091b43018760e8565f8b4ca732dc5632e7749c56b560caccf94ab6880b88887a5d9d1ffe34dbd2d5704df8daa1f0fb00c2719823ed9485b7a19e2434c5ab63221b8c813e794159daedc3a5e5c1953d5b5cb1933c6b5e509b27cb2625b271ce5bb253adebe6d6e35c3a9f69401cfd6a7685d8f4e4d0d0e662ea8767f96bb70db00b7f92c106ccb7a18b1c4a'\n\nKAGGLE_INPUT_PATH='/kaggle/input'\nKAGGLE_WORKING_PATH='/kaggle/working'\nKAGGLE_SYMLINK='kaggle'\n\n!umount /kaggle/input/ 2> /dev/null\nshutil.rmtree('/kaggle/input', ignore_errors=True)\nos.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\nos.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n\ntry:\n  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\nexcept FileExistsError:\n  pass\ntry:\n  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\nexcept FileExistsError:\n  pass\n\nfor data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n    directory, download_url_encoded = data_source_mapping.split(':')\n    download_url = unquote(download_url_encoded)\n    filename = urlparse(download_url).path\n    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n    try:\n        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n            total_length = fileres.headers['content-length']\n            print(f'Downloading {directory}, {total_length} bytes compressed')\n            dl = 0\n            data = fileres.read(CHUNK_SIZE)\n            while len(data) > 0:\n                dl += len(data)\n                tfile.write(data)\n                done = int(50 * dl / int(total_length))\n                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n                sys.stdout.flush()\n                data = fileres.read(CHUNK_SIZE)\n            if filename.endswith('.zip'):\n              with ZipFile(tfile) as zfile:\n                zfile.extractall(destination_path)\n            else:\n              with tarfile.open(tfile.name) as tarfile:\n                tarfile.extractall(destination_path)\n            print(f'\\nDownloaded and uncompressed: {directory}')\n    except HTTPError as e:\n        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n        continue\n    except OSError as e:\n        print(f'Failed to load {download_url} to path {destination_path}')\n        continue\n\nprint('Data source import complete.')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X40Sj2e4ygb_","outputId":"f9ebfba7-24e4-449e-da8b-1af1f2c81d76"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Downloading tomatoleaf, 187559775 bytes compressed\n\n[==================================================] 187559775 bytes downloaded\n\nDownloaded and uncompressed: tomatoleaf\n\nData source import complete.\n"}]},{"cell_type":"code","source":"!pip install einops --trusted-host pypi.org --trusted-host files.pythonhosted.org\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvZIH_XmygcM","outputId":"ee71b271-8c3f-4ba7-89e8-91dd794594aa","trusted":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"}]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"id":"i82JPBagygcR","trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Ensure we use GPU if available\ndevice_name = tf.test.gpu_device_name()\nprint(f'Using device: {device_name}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M2pw_ee7ygcU","outputId":"f87703bf-0460-463d-a651-c364a121e29f","trusted":true},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"Using device: /device:GPU:0\n"}]},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"id":"uN6kxJ0HygcV"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nfrom einops.layers.torch import Rearrange\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n\nclass HardDistillationLoss(nn.Module):\n    def __init__(self, teacher, n_classes=10, device='cuda'): # Add device argument\n        super().__init__()\n        self.teacher = teacher.to(device) # Move teacher to device\n        self.criterion = nn.CrossEntropyLoss()\n        self.n_classes = n_classes\n        # Add a projection layer to map teacher logits to student's class range\n        self.projection = nn.Linear(1000, n_classes).to(device)\n\n    def forward(self, inputs, outputs, labels):\n        base_loss = self.criterion(outputs[0], labels)\n\n        with torch.no_grad():\n            teacher_outputs = self.teacher(inputs)\n            # Project teacher logits to student's class range\n            projected_logits = self.projection(teacher_outputs)\n            teacher_labels = torch.argmax(projected_logits, dim=1)\n        teacher_loss = self.criterion(outputs[1], teacher_labels)\n\n        return 0.5 * base_loss + 0.5 * teacher_loss\n\n","metadata":{"id":"4ZdBwxbfygcW","trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Distillation Token","metadata":{"id":"MU4FyWb9ygcY"}},{"cell_type":"code","source":"","metadata":{"id":"T-2mDCFQygcb","trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class PatchEmbedding(nn.Module):\n    def __init__(self, in_channels, patch_size, emb_size, img_size, device='cuda'):  # Add device as a parameter\n        super().__init__()\n        self.projection = nn.Sequential(\n            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n            Rearrange('b e (h) (w) -> b (h w) e'),\n        ).to(device)\n        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size).to(device))  # Move to device\n        self.dist_token = nn.Parameter(torch.randn(1, 1, emb_size).to(device))  # Move to device\n        self.positions = nn.Parameter(torch.randn((img_size // patch_size)**2 + 2, emb_size).to(device))  # Move to device\n\n\n    def forward(self, x):\n        b = x.shape[0]\n        x = self.projection(x)\n        cls_tokens = self.cls_token.expand(b, -1, -1)\n        dist_tokens = self.dist_token.expand(b, -1, -1)\n        x = torch.cat((cls_tokens, dist_tokens, x), dim=1)\n        x += self.positions\n        return x\n\n","metadata":{"id":"V83e5snAygcc","trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class ResidualAdd(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n\n    def forward(self, x, **kwargs):\n        return x + self.fn(x, **kwargs)\n","metadata":{"id":"lBxMU9Uhygce","trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class FeedForwardBlock(nn.Sequential):\n    def __init__(self, emb_size, expansion=4, drop_p=0.):\n        super().__init__(\n            nn.Linear(emb_size, expansion * emb_size),\n            nn.GELU(),\n            nn.Dropout(drop_p),\n            nn.Linear(expansion * emb_size, emb_size),\n        )\n","metadata":{"id":"DW7ccPFUygcf","trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoderBlock(nn.Sequential):\n    def __init__(self, emb_size=768, drop_p=0., forward_expansion=4, forward_drop_p=0., **kwargs):\n        super().__init__(\n            ResidualAdd(nn.Sequential(\n                nn.LayerNorm(emb_size),\n                MultiHeadAttention(emb_size, **kwargs),\n                nn.Dropout(drop_p)\n            )),\n            ResidualAdd(nn.Sequential(\n                nn.LayerNorm(emb_size),\n                FeedForwardBlock(emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n                nn.Dropout(drop_p)\n            ))\n        )\n","metadata":{"id":"I4yKOgUsygcg","trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class DeiT(nn.Module):\n    def __init__(self, in_channels, patch_size, emb_size, img_size, depth, n_classes, device):\n        super().__init__()\n        # Pass the device to the PatchEmbedding\n        self.patch_embedding = PatchEmbedding(in_channels, patch_size, emb_size, img_size).to(device)  # Move to device\n        # Pass emb_size as a keyword argument\n        self.transformer_encoder = TransformerEncoder(depth, emb_size=emb_size).to(device)  # Move to device\n        self.classification_head = ClassificationHead(emb_size, n_classes, device).to(device)\n\n    def forward(self, x):\n      x = self.patch_embedding(x)\n      x = self.transformer_encoder(x)\n      return self.classification_head(x)\n","metadata":{"id":"oUIHFhB4ygcg","trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"img_size = 224\nbatch_size = 16\nin_channels = 3\npatch_size = 16\nemb_size = 768\ndepth = 12\nn_classes = 10\n\n# Check the range of your labels\ndef check_labels(labels):\n    if torch.any(labels < 0) or torch.any(labels >= n_classes):\n        print(\"Error: Found labels out of range!\")\n        print(f\"Labels: {labels}\")\n        return False\n    return True\n\n    if check_labels(labels):\n        print(\"Labels are within the valid range.\")\n    else:\n        print(\"Invalid labels detected.\")\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = ImageFolder('/kaggle/input/tomatoleaf/tomato/train', transform=train_transform)\nval_dataset = ImageFolder('/kaggle/input/tomatoleaf/tomato/val', transform=val_transform)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n","metadata":{"id":"mPauC3F_ygch","trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Sequential):\n    def __init__(self, depth=12, **kwargs):\n        super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])\n","metadata":{"id":"OBE3jbOkygci","trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Classification Head","metadata":{"id":"t96djk9Pygci"}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, emb_size=768, num_heads=8, dropout=0.):\n        super().__init__()\n        self.emb_size = emb_size\n        self.num_heads = num_heads\n        self.qkv = nn.Linear(emb_size, emb_size * 3)\n        self.att_drop = nn.Dropout(dropout)\n        self.projection = nn.Linear(emb_size, emb_size)\n\n    def forward(self, x, mask=None):\n        qkv = self.qkv(x).chunk(3, dim=-1)\n        queries, keys, values = map(lambda t: t.view(t.shape[0], t.shape[1], self.num_heads, self.emb_size // self.num_heads).transpose(1, 2), qkv)\n        scores = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) / (self.emb_size ** (1 / 2))\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, float('-inf'))\n        attn = self.att_drop(F.softmax(scores, dim=-1))\n        out = torch.einsum('bhqk, bhvd -> bhqd', attn, values).transpose(1, 2).contiguous().view(x.shape[0], x.shape[1], self.emb_size)\n        return self.projection(out)\n","metadata":{"id":"vuKrMtQxygcj","trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class ClassificationHead(nn.Module):\n    def __init__(self, emb_size=768, n_classes=10, device='cuda'): # Add device as argument\n        super().__init__()\n        self.head = nn.Linear(emb_size, n_classes).to(device) # Move head to device\n        self.dist_head = nn.Linear(emb_size, n_classes).to(device) # Move dist_head to device\n\n    def forward(self, x):\n        x, x_dist = x[:, 0], x[:, 1]\n        x_head = self.head(x)\n        x_dist_head = self.dist_head(x_dist)\n        if self.training:\n            return x_head, x_dist_head\n        else:\n            return (x_head + x_dist_head) / 2\n\n","metadata":{"id":"SsflX7Vtygck","trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import gc\nfrom torchvision.models import resnet50, ResNet50_Weights\n\nlearning_rate = 1e-4\nnum_epochs = 10\n\n# Define device first to be used in model instantiation\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ngc.collect()\ntorch.cuda.empty_cache()\n\nteacher = resnet50(weights=ResNet50_Weights.DEFAULT)\nteacher.eval()\nteacher.to(device)  # Move the teacher model to the GPU\n\n# Pass device to the DeiT constructor so model is created on the correct device\nstudent = DeiT(in_channels, patch_size, emb_size, img_size, depth, n_classes, device)\noptimizer = optim.Adam(student.parameters(), lr=learning_rate)\ncriterion = HardDistillationLoss(teacher, device=device)","metadata":{"id":"9O2NDcCFygcl","trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8BzlUxB4e5c","outputId":"89e80d3a-0361-4c74-b0d4-578593907533"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":"2.3.0+cu121\n"}]},{"cell_type":"markdown","source":"MultiHead Attention","metadata":{"id":"Zu50w-6qygcl"}},{"cell_type":"code","source":"# Training loop\nfor epoch in range(num_epochs):\n  student.train()\n  total_loss = 0.0\n  total_correct = 0\n\n  for inputs, labels in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n    inputs, labels = inputs.to(device), labels.to(device)\n\n    # Forward pass, explicitly moving teacher outputs to GPU\n    with torch.no_grad():  # No need to calculate gradients for teacher\n        teacher_outputs = teacher(inputs)  # inputs is already on the device\n\n    # Reduce batch size if it's too large\n    batch_size = inputs.size(0)\n    if batch_size > 16:  # Adjust this threshold as needed\n        num_splits = batch_size // 16\n        input_splits = torch.split(inputs, 16)\n        output_splits = []\n        for input_split in input_splits:\n            output_splits.append(tuple(o.to(device) for o in student(input_split)))\n        outputs = tuple(torch.cat(tensors, dim=0) for tensors in zip(*output_splits))\n    else:\n        outputs = tuple(o.to(device) for o in student(inputs))  # Move student outputs to GPU\n\n    # Compute loss\n    loss = criterion(inputs, outputs, labels)\n\n    # Backward pass and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    total_loss += loss.item()\n\n    # Calculate accuracy\n    _, predicted = torch.max(outputs[0], 1)\n    total_correct += (predicted == labels).sum().item()\n\n  # Print average loss and accuracy for the epoch\n  avg_loss = total_loss / len(train_dataloader)\n  accuracy = total_correct / len(train_dataset)\n  print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n\n# Save the trained model\ntorch.save(student.state_dict(), 'deit_student.pth')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fl52MGYJygcm","outputId":"b1892fa1-2ff8-474a-995e-a6aefeb41638","trusted":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":"Epoch 1/10:  45%|████▍     | 279/625 [02:59<03:39,  1.58it/s]"}]},{"cell_type":"markdown","source":"Model Definition","metadata":{"id":"5bxOcTIXygcn"}},{"cell_type":"code","source":"student.eval()\n\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for inputs, labels in tqdm(val_dataloader, desc='Evaluation'):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = student(inputs)\n        _, predicted = torch.max(outputs, 1)\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\naccuracy = accuracy_score(y_true, y_pred)\ncm = confusion_matrix(y_true, y_pred)\nprecision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n\nprint(f'Validation Accuracy: {accuracy:.4f}')\nprint(f'Confusion Matrix:\\n{cm}')\nprint(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}')\n\n\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\n","metadata":{"id":"rzIBDEgVygcn","trusted":true},"execution_count":null,"outputs":[]}]}